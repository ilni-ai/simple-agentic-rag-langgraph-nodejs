# ğŸ§  LangGraph.js Agentic RAG App (April 2025 Edition)

This is a full-stack AI assistant application that demonstrates the use of **LangGraph.js**, **Gemini API**, **FAISS vector search**, and **React Vite Bootstrap UI** to build a simple yet agentic Retrieval-Augmented Generation (RAG) app.

## ğŸš€ Features

---

## ğŸ–¼ï¸ Sample UI

![App UI](screenshots/sample-ui.png)

---


- âœ… Graph-based state orchestration with LangGraph.js
- âœ… Contextual retrieval using FAISS + semantic embedding (Gemini)
- âœ… Persistent multi-turn memory using SQLite
- âœ… Follow-up question generation (Gemini)
- âœ… Optional conversation summarization
- âœ… Clean React UI with follow-up buttons and summarization toggle

---

## ğŸ—‚ Project Structure

```
â”œâ”€â”€ backend-langgraphjs/
â”‚   â”œâ”€â”€ basicGraph.js       # LangGraph state graph
â”‚   â”œâ”€â”€ server.js           # Express.js server API
â”‚   â”œâ”€â”€ data/docs.txt       # Source documents to embed
â”‚   â””â”€â”€ vector-index/       # FAISS vector store index (auto generated)
â”œâ”€â”€ frontend-react/
â”‚   â””â”€â”€ App.jsx             # React Vite frontend
```

---

## ğŸ§  LangGraph Overview

This app uses LangGraph.js to construct the following graph-based workflow:

```
[START]
   â†“
[retrieve] â†’ Get relevant chunks from FAISS
   â†“
[generate] â†’ Use Gemini to respond using context + memory
   â†“
[suggest] â†’ Suggest follow-up questions (Gemini)
   â†“
[summarize] â†’ Auto-summary if triggered
   â†“
[END]
```

Each node takes in a shared `state` and contributes part of the logic.

---

## ğŸ“¦ Setup Instructions

### 1. Backend

```bash
cd backend-langgraphjs
npm install
touch .env
# Add: GEMINI_API_KEY=your_google_key_here
npm run dev
```

### 2. Frontend

```bash
cd agentic-frontend
npm install
npm run dev
```

---

## ğŸ’¡ Sample Code: Node Definition

```js
async function generate(state) {
  const { question, sessionId, context } = state;
  const history = await getChatHistory(sessionId);
  const prompt = `Context:\n${context}\n\n${historyText}\n\nQ: ${question}`;
  const answer = await invokeGemini(prompt, "generate");
  await saveToMemory(sessionId, question, answer);
  return { answer };
}
```

---

## ğŸ§ª Best Practices (April 2025)

| Design Choice     | Why Itâ€™s Good |
|-------------------|---------------|
| âœ… LangGraph.js    | Modular, maintainable, agent-like behavior |
| âœ… FAISS Vector DB | Fast, persistent, realistic for RAG |
| âœ… Gemini 2.0 Flash | Fast + reliable + rich multi-turn context |
| âœ… React Bootstrap | Quick, clean UI |
| âœ… SQLite for chat | Simple persistence with ordering + timestamps |

---

## âœ¨ Extension Ideas

- Add reflection node to evaluate and possibly re-query
- Show graph visualization of steps on frontend
- Support feedback (thumbs up/down)
- Integrate Gemini multimodal (image + text)

---
